{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import types\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root = '.', train = True, download = True)\n",
    "valid_dataset = datasets.MNIST(root = '.', train = False, download = True)\n",
    "train_dataset.data = train_dataset.data.to(torch.float)\n",
    "valid_dataset.data = valid_dataset.data.to(torch.float)\n",
    "\n",
    "mean, std = train_dataset.data.mean(), train_dataset.data.std()\n",
    "train_data = data.TensorDataset( (train_dataset.data-mean)/std, train_dataset.targets)\n",
    "valid_data = data.TensorDataset( (valid_dataset.data-mean)/std, valid_dataset.targets)\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size = 100, shuffle = True,  num_workers = 4, pin_memory=True)\n",
    "valid_loader = data.DataLoader(valid_data, batch_size = 500, shuffle = False, num_workers = 4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerFlatten(torch.nn.Module):\n",
    "    def forward(self, x): return x.view(x.shape[0], -1)\n",
    "    \n",
    "class LayerThicken(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        if x.dim()==4:\n",
    "            return x\n",
    "        if x.dim()==3:\n",
    "            return x[:,None,:,:]\n",
    "        if x.dim()==2:\n",
    "            n, m = x.shape\n",
    "            return x[n, None, int(m**0.5), m-int(m**0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeNet300_100():\n",
    "    model = nn.Sequential(\n",
    "        LayerFlatten(),\n",
    "        nn.Linear(784, 300),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(300, 100),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(100, 10),\n",
    "        nn.LogSoftmax(dim=-1))\n",
    "    return model\n",
    "\n",
    "def LeNet5():\n",
    "    model = nn.Sequential( # 1, 28, 28\n",
    "        LayerThicken(), \n",
    "        nn.Conv2d(1, 6, kernel_size=5, padding=2), # 6, 28, 28\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2), # 6, 14, 14\n",
    "        nn.Conv2d(6, 16, kernel_size=5), # 16, 10, 10\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2), # 16, 5, 5\n",
    "        LayerFlatten(),\n",
    "        nn.Linear(400,120),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(120, 84),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(84, 10),\n",
    "        nn.LogSoftmax(dim=-1)) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNIP_official:\n",
    "    def __init__(self, model):\n",
    "        \n",
    "        self.model = model\n",
    "        self.pruned = []\n",
    "        \n",
    "        for layer in model.modules():\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)\n",
    "                layer.indicator = torch.ones_like(layer.weight)\n",
    "                function = lambda self, x: F.linear(x, weight = self.weight * self.indicator, bias = self.bias)\n",
    "                layer.forward = types.MethodType(function, layer)\n",
    "                self.pruned.append(layer)\n",
    "                \n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                nn.init.xavier_uniform_(layer.weight)\n",
    "                layer.indicator = torch.ones_like(layer.weight)\n",
    "                function = lambda self, x: F.conv2d(x, self.weight * self.indicator, self.bias,\n",
    "                                                  self.stride, self.padding, self.dilation, self.groups)\n",
    "                layer.forward = types.MethodType(function, layer)\n",
    "                self.pruned.append(layer)\n",
    "                \n",
    "\n",
    "    def prune(self, sparsity, loader, loss=nn.CrossEntropyLoss()):\n",
    "        for layer in self.pruned:\n",
    "                layer.indicator.requires_grad = True\n",
    "                if layer.indicator.grad:\n",
    "                    layer.indicator.grad.zero_()\n",
    "        \n",
    "        for x, y in loader:\n",
    "            x = x.to(device); y = y.to(device)\n",
    "            \n",
    "            output = self.model.forward(x)\n",
    "            L = loss(output, y)\n",
    "            L.backward()\n",
    "            break\n",
    "            \n",
    "        for layer in self.pruned: layer.indicator.requires_grad = False\n",
    "        model.zero_grad()\n",
    "            \n",
    "        saliences = torch.empty(0)\n",
    "        \n",
    "        \n",
    "        for layer in self.model:\n",
    "            try: saliences = torch.cat([ saliences, layer.indicator.grad.view(-1).abs().to('cpu') ])\n",
    "            except AttributeError: pass\n",
    "        \n",
    "        print('To prune', int(saliences.shape[0] * sparsity))\n",
    "        limit_value = saliences.kthvalue(k = int(saliences.shape[0] * sparsity)).values.item()\n",
    "        \n",
    "        print(\"Connections statistics:\")\n",
    "        for layer in self.pruned:\n",
    "            print( int(layer.indicator.sum().item()), end=' - ')\n",
    "            print( (layer.indicator.grad.abs() < limit_value).sum().item(), end=' = ' )\n",
    "            \n",
    "            layer.indicator[layer.indicator.grad.abs() < limit_value] = 0\n",
    "            print( (layer.indicator == 1).sum().item(), end = ' ' )\n",
    "            print(\"(\" + str(round( (layer.indicator == 1).sum().item() / layer.indicator.numel() * 100, 3)) + \"%)\")\n",
    "\n",
    "    def apply(self):\n",
    "        with torch.no_grad():\n",
    "            for layer in self.pruned:\n",
    "                layer.reset_parameters()\n",
    "                layer.weight.data *= layer.indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5()\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To prune 614\n",
      "Connections statistics:\n",
      "150 - 0 = 150 (100.0%)\n",
      "2400 - 0 = 2400 (100.0%)\n",
      "48000 - 0 = 48000 (100.0%)\n",
      "10080 - 0 = 10080 (100.0%)\n",
      "840 - 0 = 840 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "snip = SNIP_official(model)\n",
    "snip.prune(sparsity = 0.01, loader = train_loader)\n",
    "snip.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights = np.array(model[1].weight.data.cpu().view(-1))\n",
    "plt.hist(weights[weights!=0], bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, scheduler, train_loader, valid_loader, epochs=1, loss=nn.CrossEntropyLoss()):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        scheduler.step()\n",
    "        \n",
    "        model.train()\n",
    "        cumloss, cumacc, quantity, t = 0, 0, 0, time()\n",
    "        for x, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            x = x.to(device); y = y.to(device)\n",
    "            \n",
    "            probs = model.forward(x)\n",
    "            L = loss(probs, y)\n",
    "            L.backward()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                optimizer.step()\n",
    "                \n",
    "                predictions = torch.argmax(probs, dim=1)\n",
    "                accuracy = torch.sum((predictions==y).to(torch.float))\n",
    "                \n",
    "                cumloss += L.item()\n",
    "                cumacc += accuracy.item() * 100\n",
    "                quantity += predictions.shape[0]\n",
    "                \n",
    "                string = \"\\repoch {:^4} | item {:^7} | loss {:^6.3f} | accuracy {:^7.3f} | lr {:<7.5f}\"\n",
    "                print(string.format(epoch, quantity, cumloss/quantity, cumacc/quantity, optimizer.param_groups[0]['lr']), end='')\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            cumloss, cumacc, quantity = 0, 0, 0\n",
    "            for x, y in valid_loader:\n",
    "                x = x.to(device); y = y.to(device)\n",
    "\n",
    "                probs = model.forward(x)\n",
    "                L = loss(probs, y)\n",
    "\n",
    "                predictions = torch.argmax(probs, dim=1)\n",
    "                accuracy = torch.sum((predictions==y).to(torch.float))\n",
    "\n",
    "                cumloss += L.item()\n",
    "                cumacc += accuracy.item() * 100\n",
    "                quantity += predictions.shape[0]\n",
    "\n",
    "            string = \" || loss {:^7.4f} | accuracy {:^7.4f}\"\n",
    "            print(string.format(cumloss/quantity, cumacc/quantity), end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr = 0.1, momentum = 0.9, weight_decay = 1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0   | item  60000  | loss 0.003  | accuracy 91.180  | lr 0.08000 || loss 0.0002  | accuracy 97.6800\n",
      "epoch  1   | item  60000  | loss 0.001  | accuracy 97.763  | lr 0.06400 || loss 0.0001  | accuracy 98.3000\n",
      "epoch  2   | item  60000  | loss 0.000  | accuracy 98.653  | lr 0.05120 || loss 0.0001  | accuracy 98.3800\n",
      "epoch  3   | item  60000  | loss 0.000  | accuracy 98.913  | lr 0.04096 || loss 0.0001  | accuracy 98.6200\n",
      "epoch  4   | item  60000  | loss 0.000  | accuracy 99.203  | lr 0.03277 || loss 0.0001  | accuracy 98.6600\n",
      "epoch  5   | item  60000  | loss 0.000  | accuracy 99.448  | lr 0.02621 || loss 0.0001  | accuracy 98.9900\n",
      "epoch  6   | item  60000  | loss 0.000  | accuracy 99.602  | lr 0.02097 || loss 0.0001  | accuracy 98.9700\n",
      "epoch  7   | item  60000  | loss 0.000  | accuracy 99.723  | lr 0.01678 || loss 0.0001  | accuracy 98.9900\n",
      "epoch  8   | item  60000  | loss 0.000  | accuracy 99.797  | lr 0.01342 || loss 0.0001  | accuracy 99.0600\n",
      "epoch  9   | item  60000  | loss 0.000  | accuracy 99.860  | lr 0.01074 || loss 0.0001  | accuracy 99.0200\n",
      "epoch  10  | item  60000  | loss 0.000  | accuracy 99.888  | lr 0.00859 || loss 0.0001  | accuracy 99.0900\n",
      "epoch  11  | item  60000  | loss 0.000  | accuracy 99.917  | lr 0.00687 || loss 0.0001  | accuracy 99.0800\n",
      "epoch  12  | item  60000  | loss 0.000  | accuracy 99.922  | lr 0.00550 || loss 0.0001  | accuracy 99.0500\n",
      "epoch  13  | item  60000  | loss 0.000  | accuracy 99.932  | lr 0.00440 || loss 0.0001  | accuracy 99.0700\n",
      "epoch  14  | item  60000  | loss 0.000  | accuracy 99.938  | lr 0.00352 || loss 0.0001  | accuracy 99.0600\n",
      "epoch  15  | item  60000  | loss 0.000  | accuracy 99.943  | lr 0.00281 || loss 0.0001  | accuracy 99.0300\n",
      "epoch  16  | item  60000  | loss 0.000  | accuracy 99.948  | lr 0.00225 || loss 0.0001  | accuracy 99.0700\n",
      "epoch  17  | item  60000  | loss 0.000  | accuracy 99.950  | lr 0.00180 || loss 0.0001  | accuracy 99.0800\n",
      "epoch  18  | item  60000  | loss 0.000  | accuracy 99.955  | lr 0.00144 || loss 0.0001  | accuracy 99.0700\n",
      "epoch  19  | item  60000  | loss 0.000  | accuracy 99.953  | lr 0.00115 || loss 0.0001  | accuracy 99.0700\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, scheduler, train_loader, valid_loader, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
